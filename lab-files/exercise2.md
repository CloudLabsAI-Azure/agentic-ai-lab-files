# Exercise 2: Enhancing AI Agents with Multi-Modal Capabilities

### Estimated Duration: 60 Minutes

## Lab Scenario

In this exercise, you will extend an AI Agent with AI Services to process voice, images, and text. You will integrate Speech-to-Text and Text-to-Speech capabilities to enable voice-based AI interactions. Additionally, you will leverage the Computer Vision API to analyze and process images. By combining text, voice, and image inputs, you will enhance the AI Agentâ€™s responses, making it more interactive and intelligent. Finally, you will validate the Multi-Modal AI Agent using sample inputs to ensure its effectiveness.

## Objectives

Understand how to extend an AI Agent with AI Services to process voice, images, and text; by the end of this exercise, you will:

- Integrate Speech-to-Text & Text-to-Speech to enable voice-based AI interactions
- Use Computer Vision API to analyse and process images
- Setting up the codebase for Multimodal agent
- Validate Multi-Modal AI Agent with sample inputs

## Integrate Speech-to-Text & Text-to-Speech to enable voice-based AI interactions

In this task, you will implement voice-based interactions using the Web Speech API, enabling both speech-to-text (STT) and text-to-speech (TTS) functionalities in a web application.

1. Navigate to **Visual Studio Code**, select **file** from the top menu and click on **open folder** to open multimodal code files.

   ![](./media/ex2img8.png)